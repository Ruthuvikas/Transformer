{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF/q9W3s3uknEFBEX0btEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruthuvikas/Transformer/blob/main/Model_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantization of a tensor from fp32 to fp16"
      ],
      "metadata": {
        "id": "BbJK5fSZSCq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def quantize_example():\n",
        "    # Create a sample tensor in fp32\n",
        "    original_tensor = torch.randn(3, 4, dtype=torch.float32)\n",
        "\n",
        "    print(\"Original Tensor (FP32):\")\n",
        "    print(\"Dtype:\", original_tensor.dtype)\n",
        "    print(\"Values:\", original_tensor)\n",
        "    print(\"Memory usage (bytes):\", original_tensor.element_size() * original_tensor.nelement())\n",
        "\n",
        "    # Convert to fp16\n",
        "    quantized_tensor = original_tensor.half()\n",
        "\n",
        "    print(\"\\nQuantized Tensor (FP16):\")\n",
        "    print(\"Dtype:\", quantized_tensor.dtype)\n",
        "    print(\"Values:\", quantized_tensor)\n",
        "    print(\"Memory usage (bytes):\", quantized_tensor.element_size() * quantized_tensor.nelement())\n",
        "\n",
        "    # Demonstrate precision loss\n",
        "    print(\"\\nPrecision Comparison:\")\n",
        "    print(\"Max absolute difference:\",\n",
        "          torch.max(torch.abs(original_tensor - quantized_tensor.float())).item())\n",
        "\n",
        "# Run the demonstration\n",
        "quantize_example()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-wjVYXiQBa8",
        "outputId": "52c75f1b-d3f2-4a19-da9f-dc65049c33df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor (FP32):\n",
            "Dtype: torch.float32\n",
            "Values: tensor([[ 0.3416,  1.3372,  0.1772,  0.8209],\n",
            "        [-1.0045,  0.2167, -0.8730, -0.4546],\n",
            "        [-0.4399, -1.0325, -0.2025, -2.4493]])\n",
            "Memory usage (bytes): 48\n",
            "\n",
            "Quantized Tensor (FP16):\n",
            "Dtype: torch.float16\n",
            "Values: tensor([[ 0.3416,  1.3369,  0.1772,  0.8208],\n",
            "        [-1.0049,  0.2167, -0.8730, -0.4546],\n",
            "        [-0.4399, -1.0322, -0.2025, -2.4492]], dtype=torch.float16)\n",
            "Memory usage (bytes): 24\n",
            "\n",
            "Precision Comparison:\n",
            "Max absolute difference: 0.0003980398178100586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning"
      ],
      "metadata": {
        "id": "q90sP5R53-3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, criterion, and optimizer\n",
        "model = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Example input and target\n",
        "x = torch.randn(5, 10)\n",
        "y = torch.randn(5, 1)\n",
        "\n",
        "# Apply pruning to the first layer\n",
        "print(\"Before pruning:\")\n",
        "print(model.fc1.weight)\n",
        "\n",
        "prune.l1_unstructured(model.fc1, name=\"weight\", amount=0.3)  # Prune 30% of the weights\n",
        "\n",
        "print(\"After pruning:\")\n",
        "print(model.fc1.weight)\n",
        "print(\"Pruned mask:\")\n",
        "print(model.fc1.weight_mask)\n",
        "\n",
        "# Train the model with pruned weights\n",
        "for epoch in range(5):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(x)\n",
        "    loss = criterion(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Remove pruning reparameterization if needed\n",
        "prune.remove(model.fc1, name=\"weight\")\n",
        "print(\"After removing pruning:\")\n",
        "print(model.fc1.weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_JjrLij4AL7",
        "outputId": "1d8d002e-4a3b-48c8-f617-cc555f33cff5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before pruning:\n",
            "Parameter containing:\n",
            "tensor([[-7.0054e-02,  9.8435e-02,  7.0166e-03,  2.2374e-01,  9.3290e-02,\n",
            "         -1.5916e-01,  1.4244e-01,  6.4996e-02, -1.1214e-01,  1.5585e-01],\n",
            "        [-2.0116e-01,  2.6917e-01,  3.4827e-02, -6.3969e-02, -9.6950e-02,\n",
            "          2.0849e-01, -1.3459e-01, -1.0771e-01,  3.6854e-02,  2.5579e-01],\n",
            "        [ 1.5962e-02, -1.4013e-01,  2.3676e-01, -8.4859e-02,  5.5687e-02,\n",
            "         -2.8981e-02,  1.1660e-01, -1.6555e-01,  3.0106e-01,  9.1430e-02],\n",
            "        [-2.1639e-01, -1.7182e-01, -8.1013e-02, -3.0091e-01,  1.2596e-01,\n",
            "         -8.3394e-02,  2.7196e-01,  1.6595e-01, -1.4153e-01,  1.9702e-01],\n",
            "        [-3.0436e-01,  1.7374e-01,  1.3569e-01, -2.0500e-01, -3.1268e-01,\n",
            "          1.7759e-01,  1.2436e-01,  3.5675e-02,  2.6614e-01, -2.2584e-01],\n",
            "        [-2.2002e-01, -2.3496e-01,  2.9489e-01, -2.7864e-01, -2.2025e-02,\n",
            "          1.5598e-01,  2.5190e-01, -1.1827e-01,  1.9689e-01, -2.3368e-01],\n",
            "        [ 5.9743e-04, -1.2529e-01,  2.1133e-01, -2.8118e-01,  2.5549e-01,\n",
            "          3.0271e-01,  1.3828e-01,  2.1055e-01,  1.6235e-01, -2.1728e-01],\n",
            "        [-1.7604e-01,  1.1793e-01,  8.2724e-02,  2.8181e-01,  6.0295e-02,\n",
            "          1.6458e-01, -1.3615e-01, -4.9430e-02, -2.9438e-01, -9.8153e-02],\n",
            "        [ 1.3816e-01,  2.6013e-01, -7.2921e-02, -1.0475e-01,  6.1032e-02,\n",
            "          4.5389e-02, -2.3871e-01, -1.8471e-01, -2.3411e-01, -2.0377e-01],\n",
            "        [-9.9380e-02, -5.1394e-02,  1.7761e-01, -1.2015e-01, -2.7504e-01,\n",
            "         -6.5406e-02, -2.8510e-01, -1.6843e-01, -2.5966e-01,  1.2247e-01],\n",
            "        [-3.0875e-01, -3.0052e-01,  5.5953e-03,  7.9752e-02,  2.1767e-01,\n",
            "         -1.6024e-01, -2.2418e-01, -3.8500e-02, -2.7548e-01,  2.1056e-01],\n",
            "        [ 6.2603e-02, -1.5098e-01, -8.2717e-02, -4.0698e-03, -1.4602e-02,\n",
            "          2.9613e-01,  1.7060e-01,  1.2892e-01, -1.6789e-01,  2.6072e-01],\n",
            "        [-2.6288e-02,  1.7270e-01,  9.1052e-02, -2.6832e-01, -6.6908e-02,\n",
            "         -2.7401e-01, -5.6093e-02, -2.1785e-02,  1.7042e-01,  1.0943e-01],\n",
            "        [ 8.6538e-02, -1.7617e-01, -1.0677e-01, -1.5483e-01,  1.8167e-01,\n",
            "          2.5619e-01, -2.4292e-01, -2.4208e-01, -1.0292e-02, -8.0161e-02],\n",
            "        [ 1.0117e-01, -1.1433e-01, -1.0658e-01, -2.1450e-01, -9.3320e-02,\n",
            "         -4.2263e-02,  7.7698e-02,  2.4316e-01,  2.3301e-01,  3.0214e-01],\n",
            "        [-2.4542e-01,  2.9196e-01, -3.1010e-01,  1.3187e-01, -2.7447e-01,\n",
            "          1.4607e-01, -4.3508e-03, -1.7774e-01, -2.3931e-01, -2.1382e-01],\n",
            "        [ 1.5572e-01,  3.1970e-02,  2.4751e-01, -1.9655e-01, -1.8280e-01,\n",
            "          2.2281e-01,  1.6057e-01, -2.9746e-01,  8.5533e-02, -9.6070e-02],\n",
            "        [ 7.0048e-02, -2.5790e-01,  1.5033e-01, -2.1178e-01,  3.2737e-02,\n",
            "          2.2545e-01,  3.0180e-01, -9.0562e-02, -9.6680e-02,  7.0911e-02],\n",
            "        [ 6.1677e-02,  1.9903e-01,  1.0273e-01, -1.0769e-02, -1.8254e-01,\n",
            "          1.8781e-01, -1.2471e-01, -2.8415e-01,  2.8845e-01, -1.0579e-01],\n",
            "        [-1.0018e-01,  2.1613e-01, -8.0322e-03,  2.6334e-01,  2.9496e-01,\n",
            "          2.5581e-01, -2.9743e-02, -1.3691e-01,  4.7282e-02,  5.8322e-02],\n",
            "        [ 2.4538e-01, -1.0667e-02,  1.0858e-01,  2.0021e-01, -3.0863e-01,\n",
            "         -3.0428e-01,  1.0129e-01, -1.4257e-01,  1.3247e-01,  7.8337e-02],\n",
            "        [ 2.8141e-01,  1.0898e-01, -3.1144e-02, -2.7741e-01, -1.6589e-02,\n",
            "          8.4628e-02, -1.1152e-01,  1.0393e-01,  6.2741e-02,  3.1931e-02],\n",
            "        [-1.2056e-01, -2.0528e-01,  2.6733e-01,  1.3153e-01,  1.7122e-02,\n",
            "          1.9198e-01,  3.7777e-02, -3.1104e-02,  3.1089e-01, -1.9769e-01],\n",
            "        [ 8.1468e-02,  2.9015e-01,  7.6277e-02, -2.9272e-01,  3.0988e-01,\n",
            "          4.2366e-02, -2.3782e-01, -4.6818e-02,  4.8615e-02,  1.5646e-01],\n",
            "        [ 2.6604e-01,  2.0517e-02, -2.0400e-01,  1.7587e-01,  2.3492e-01,\n",
            "         -1.9533e-01,  3.0960e-01, -1.5839e-01,  1.4927e-01, -2.4156e-01],\n",
            "        [ 3.1506e-01, -1.5091e-01, -6.3745e-02, -2.6377e-01,  4.6744e-03,\n",
            "         -2.3861e-01, -3.0771e-01,  3.9435e-02, -3.2677e-02,  1.5975e-01],\n",
            "        [-3.0075e-01,  1.3155e-01, -3.1514e-01, -2.7746e-02,  5.2107e-02,\n",
            "         -6.3316e-02,  6.6943e-02, -2.5890e-01,  1.4832e-01,  3.1156e-01],\n",
            "        [-2.7148e-01, -4.5302e-02,  3.1614e-01, -2.8741e-02,  1.4865e-01,\n",
            "          8.9479e-02, -1.8038e-01, -1.3361e-01,  1.5735e-01,  1.4626e-01],\n",
            "        [-8.1443e-02,  1.4102e-01,  5.3545e-02, -1.3629e-01, -1.6305e-01,\n",
            "          2.1518e-01,  1.6812e-01,  1.9541e-01, -1.8944e-02, -2.3857e-01],\n",
            "        [-2.9806e-01,  1.5412e-01, -1.1109e-01, -2.2561e-01,  5.1301e-02,\n",
            "         -2.0735e-01,  1.4247e-01, -1.8894e-01,  7.6742e-02,  1.0082e-01],\n",
            "        [ 9.0508e-02,  1.5592e-01,  6.8298e-02,  8.3451e-02, -1.7731e-01,\n",
            "         -3.7915e-02,  1.1332e-01,  2.0966e-01,  2.2223e-01, -4.7303e-02],\n",
            "        [ 2.7628e-01,  1.9055e-01,  2.1118e-01,  2.0585e-01, -4.2310e-02,\n",
            "         -2.9384e-01,  2.1712e-01,  1.2071e-01, -1.5291e-01,  2.4833e-01],\n",
            "        [-2.8848e-01,  2.1511e-01,  2.4584e-01, -1.5414e-01, -7.8274e-02,\n",
            "         -8.9397e-02,  2.3233e-01,  4.0541e-02, -3.1024e-01,  2.1936e-01],\n",
            "        [ 1.2133e-01, -1.6156e-02,  4.5953e-02,  1.7959e-01,  3.0672e-02,\n",
            "          1.7706e-01, -2.6691e-01,  3.1025e-01, -2.1405e-03,  1.2403e-01],\n",
            "        [ 5.7544e-02, -1.4372e-01, -5.9837e-03, -2.6008e-02,  2.0524e-01,\n",
            "          2.8683e-02,  2.1242e-01,  8.3310e-02,  4.8611e-04,  1.0870e-01],\n",
            "        [-2.0816e-01,  3.7139e-02,  3.0693e-01,  1.4599e-01,  3.0259e-01,\n",
            "         -2.3375e-01,  1.9573e-01, -1.0780e-01,  1.6911e-01, -1.3866e-01],\n",
            "        [ 5.9943e-02,  1.1562e-01, -1.1017e-01, -2.4732e-01, -7.5407e-02,\n",
            "         -1.9227e-01,  4.1208e-02,  1.3053e-01,  2.9726e-01,  3.3109e-03],\n",
            "        [ 1.3151e-01,  3.2563e-02,  3.1460e-01,  3.7028e-02, -1.8816e-01,\n",
            "         -7.3602e-02, -1.8503e-01,  4.1279e-04,  9.6840e-02, -2.5771e-01],\n",
            "        [ 3.0426e-02, -1.4865e-01, -2.1560e-01, -1.6360e-01, -2.4001e-02,\n",
            "         -1.6938e-01, -6.4741e-02,  2.2749e-01, -1.9721e-01,  7.8916e-02],\n",
            "        [ 9.7192e-02,  1.7900e-01, -2.6150e-02, -6.3107e-02, -1.9504e-01,\n",
            "         -2.9764e-01, -1.1908e-01,  7.5891e-03, -6.6090e-02,  1.9991e-01],\n",
            "        [ 1.1330e-01, -2.8613e-01,  2.8287e-01,  2.3440e-04, -3.3598e-02,\n",
            "         -2.5304e-01, -1.2160e-01,  1.7120e-02, -9.7695e-02,  1.0620e-01],\n",
            "        [-2.3361e-01, -9.3029e-02, -2.7685e-03,  1.4001e-01,  1.1866e-01,\n",
            "          4.0382e-03,  2.7837e-01,  2.0097e-01, -1.7235e-01,  1.5977e-01],\n",
            "        [-1.8537e-01,  1.9207e-01, -2.7772e-01, -6.5043e-03, -2.7236e-01,\n",
            "          1.9515e-02,  3.1091e-01, -1.1211e-01,  5.5766e-03, -6.7411e-03],\n",
            "        [-2.2321e-01, -2.1651e-01, -1.2748e-01,  1.7053e-01,  2.3833e-01,\n",
            "         -2.9826e-01,  1.4307e-01, -2.4023e-01,  9.9098e-02, -2.7477e-01],\n",
            "        [-1.2746e-01, -1.4761e-01, -1.4240e-01, -1.1620e-01,  2.5895e-01,\n",
            "         -4.4976e-02,  3.2432e-02,  1.1778e-01,  7.0445e-02, -1.8397e-01],\n",
            "        [ 2.3639e-01, -2.3942e-01, -2.1555e-01,  8.3084e-02,  1.2981e-01,\n",
            "         -1.1100e-01,  1.3687e-01,  1.1058e-01, -2.9313e-01,  3.7568e-02],\n",
            "        [ 7.6481e-02,  3.0369e-01,  3.0503e-01, -1.5945e-01, -2.9760e-01,\n",
            "         -4.2800e-02,  9.9839e-02,  1.2132e-01, -1.1892e-01, -1.0986e-01],\n",
            "        [-1.8902e-01,  2.4910e-01,  1.7345e-01, -4.3677e-02,  9.8426e-02,\n",
            "         -2.3325e-01,  5.3649e-02, -1.3193e-01, -7.5349e-02,  2.8428e-01],\n",
            "        [-2.3439e-01, -5.1897e-03,  2.0436e-01,  3.0735e-01, -8.9993e-02,\n",
            "          1.8739e-03, -3.0363e-01,  4.7983e-02, -2.9323e-01,  2.9764e-01],\n",
            "        [-1.0193e-01, -2.9089e-01,  1.9566e-01,  1.8322e-01,  5.2672e-02,\n",
            "          1.3087e-01,  3.1175e-01,  6.4519e-02, -4.4490e-02,  2.4333e-01]],\n",
            "       requires_grad=True)\n",
            "After pruning:\n",
            "tensor([[-0.0000,  0.0984,  0.0000,  0.2237,  0.0000, -0.1592,  0.1424,  0.0000,\n",
            "         -0.1121,  0.1559],\n",
            "        [-0.2012,  0.2692,  0.0000, -0.0000, -0.0970,  0.2085, -0.1346, -0.1077,\n",
            "          0.0000,  0.2558],\n",
            "        [ 0.0000, -0.1401,  0.2368, -0.0000,  0.0000, -0.0000,  0.1166, -0.1656,\n",
            "          0.3011,  0.0000],\n",
            "        [-0.2164, -0.1718, -0.0000, -0.3009,  0.1260, -0.0000,  0.2720,  0.1659,\n",
            "         -0.1415,  0.1970],\n",
            "        [-0.3044,  0.1737,  0.1357, -0.2050, -0.3127,  0.1776,  0.1244,  0.0000,\n",
            "          0.2661, -0.2258],\n",
            "        [-0.2200, -0.2350,  0.2949, -0.2786, -0.0000,  0.1560,  0.2519, -0.1183,\n",
            "          0.1969, -0.2337],\n",
            "        [ 0.0000, -0.1253,  0.2113, -0.2812,  0.2555,  0.3027,  0.1383,  0.2106,\n",
            "          0.1624, -0.2173],\n",
            "        [-0.1760,  0.1179,  0.0000,  0.2818,  0.0000,  0.1646, -0.1362, -0.0000,\n",
            "         -0.2944, -0.0982],\n",
            "        [ 0.1382,  0.2601, -0.0000, -0.1047,  0.0000,  0.0000, -0.2387, -0.1847,\n",
            "         -0.2341, -0.2038],\n",
            "        [-0.0994, -0.0000,  0.1776, -0.1202, -0.2750, -0.0000, -0.2851, -0.1684,\n",
            "         -0.2597,  0.1225],\n",
            "        [-0.3087, -0.3005,  0.0000,  0.0000,  0.2177, -0.1602, -0.2242, -0.0000,\n",
            "         -0.2755,  0.2106],\n",
            "        [ 0.0000, -0.1510, -0.0000, -0.0000, -0.0000,  0.2961,  0.1706,  0.1289,\n",
            "         -0.1679,  0.2607],\n",
            "        [-0.0000,  0.1727,  0.0000, -0.2683, -0.0000, -0.2740, -0.0000, -0.0000,\n",
            "          0.1704,  0.1094],\n",
            "        [ 0.0000, -0.1762, -0.1068, -0.1548,  0.1817,  0.2562, -0.2429, -0.2421,\n",
            "         -0.0000, -0.0000],\n",
            "        [ 0.1012, -0.1143, -0.1066, -0.2145, -0.0933, -0.0000,  0.0000,  0.2432,\n",
            "          0.2330,  0.3021],\n",
            "        [-0.2454,  0.2920, -0.3101,  0.1319, -0.2745,  0.1461, -0.0000, -0.1777,\n",
            "         -0.2393, -0.2138],\n",
            "        [ 0.1557,  0.0000,  0.2475, -0.1965, -0.1828,  0.2228,  0.1606, -0.2975,\n",
            "          0.0000, -0.0961],\n",
            "        [ 0.0000, -0.2579,  0.1503, -0.2118,  0.0000,  0.2255,  0.3018, -0.0000,\n",
            "         -0.0967,  0.0000],\n",
            "        [ 0.0000,  0.1990,  0.1027, -0.0000, -0.1825,  0.1878, -0.1247, -0.2841,\n",
            "          0.2884, -0.1058],\n",
            "        [-0.1002,  0.2161, -0.0000,  0.2633,  0.2950,  0.2558, -0.0000, -0.1369,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.2454, -0.0000,  0.1086,  0.2002, -0.3086, -0.3043,  0.1013, -0.1426,\n",
            "          0.1325,  0.0000],\n",
            "        [ 0.2814,  0.1090, -0.0000, -0.2774, -0.0000,  0.0000, -0.1115,  0.1039,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.1206, -0.2053,  0.2673,  0.1315,  0.0000,  0.1920,  0.0000, -0.0000,\n",
            "          0.3109, -0.1977],\n",
            "        [ 0.0000,  0.2901,  0.0000, -0.2927,  0.3099,  0.0000, -0.2378, -0.0000,\n",
            "          0.0000,  0.1565],\n",
            "        [ 0.2660,  0.0000, -0.2040,  0.1759,  0.2349, -0.1953,  0.3096, -0.1584,\n",
            "          0.1493, -0.2416],\n",
            "        [ 0.3151, -0.1509, -0.0000, -0.2638,  0.0000, -0.2386, -0.3077,  0.0000,\n",
            "         -0.0000,  0.1597],\n",
            "        [-0.3007,  0.1316, -0.3151, -0.0000,  0.0000, -0.0000,  0.0000, -0.2589,\n",
            "          0.1483,  0.3116],\n",
            "        [-0.2715, -0.0000,  0.3161, -0.0000,  0.1487,  0.0000, -0.1804, -0.1336,\n",
            "          0.1574,  0.1463],\n",
            "        [-0.0000,  0.1410,  0.0000, -0.1363, -0.1631,  0.2152,  0.1681,  0.1954,\n",
            "         -0.0000, -0.2386],\n",
            "        [-0.2981,  0.1541, -0.1111, -0.2256,  0.0000, -0.2073,  0.1425, -0.1889,\n",
            "          0.0000,  0.1008],\n",
            "        [ 0.0000,  0.1559,  0.0000,  0.0000, -0.1773, -0.0000,  0.1133,  0.2097,\n",
            "          0.2222, -0.0000],\n",
            "        [ 0.2763,  0.1906,  0.2112,  0.2058, -0.0000, -0.2938,  0.2171,  0.1207,\n",
            "         -0.1529,  0.2483],\n",
            "        [-0.2885,  0.2151,  0.2458, -0.1541, -0.0000, -0.0000,  0.2323,  0.0000,\n",
            "         -0.3102,  0.2194],\n",
            "        [ 0.1213, -0.0000,  0.0000,  0.1796,  0.0000,  0.1771, -0.2669,  0.3102,\n",
            "         -0.0000,  0.1240],\n",
            "        [ 0.0000, -0.1437, -0.0000, -0.0000,  0.2052,  0.0000,  0.2124,  0.0000,\n",
            "          0.0000,  0.1087],\n",
            "        [-0.2082,  0.0000,  0.3069,  0.1460,  0.3026, -0.2338,  0.1957, -0.1078,\n",
            "          0.1691, -0.1387],\n",
            "        [ 0.0000,  0.1156, -0.1102, -0.2473, -0.0000, -0.1923,  0.0000,  0.1305,\n",
            "          0.2973,  0.0000],\n",
            "        [ 0.1315,  0.0000,  0.3146,  0.0000, -0.1882, -0.0000, -0.1850,  0.0000,\n",
            "          0.0968, -0.2577],\n",
            "        [ 0.0000, -0.1487, -0.2156, -0.1636, -0.0000, -0.1694, -0.0000,  0.2275,\n",
            "         -0.1972,  0.0000],\n",
            "        [ 0.0972,  0.1790, -0.0000, -0.0000, -0.1950, -0.2976, -0.1191,  0.0000,\n",
            "         -0.0000,  0.1999],\n",
            "        [ 0.1133, -0.2861,  0.2829,  0.0000, -0.0000, -0.2530, -0.1216,  0.0000,\n",
            "         -0.0977,  0.1062],\n",
            "        [-0.2336, -0.0000, -0.0000,  0.1400,  0.1187,  0.0000,  0.2784,  0.2010,\n",
            "         -0.1724,  0.1598],\n",
            "        [-0.1854,  0.1921, -0.2777, -0.0000, -0.2724,  0.0000,  0.3109, -0.1121,\n",
            "          0.0000, -0.0000],\n",
            "        [-0.2232, -0.2165, -0.1275,  0.1705,  0.2383, -0.2983,  0.1431, -0.2402,\n",
            "          0.0991, -0.2748],\n",
            "        [-0.1275, -0.1476, -0.1424, -0.1162,  0.2590, -0.0000,  0.0000,  0.1178,\n",
            "          0.0000, -0.1840],\n",
            "        [ 0.2364, -0.2394, -0.2156,  0.0000,  0.1298, -0.1110,  0.1369,  0.1106,\n",
            "         -0.2931,  0.0000],\n",
            "        [ 0.0000,  0.3037,  0.3050, -0.1594, -0.2976, -0.0000,  0.0998,  0.1213,\n",
            "         -0.1189, -0.1099],\n",
            "        [-0.1890,  0.2491,  0.1734, -0.0000,  0.0984, -0.2333,  0.0000, -0.1319,\n",
            "         -0.0000,  0.2843],\n",
            "        [-0.2344, -0.0000,  0.2044,  0.3074, -0.0000,  0.0000, -0.3036,  0.0000,\n",
            "         -0.2932,  0.2976],\n",
            "        [-0.1019, -0.2909,  0.1957,  0.1832,  0.0000,  0.1309,  0.3118,  0.0000,\n",
            "         -0.0000,  0.2433]], grad_fn=<MulBackward0>)\n",
            "Pruned mask:\n",
            "tensor([[0., 1., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 1., 0., 1., 1., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [0., 1., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
            "        [0., 1., 0., 1., 0., 1., 0., 0., 1., 1.],\n",
            "        [0., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 1., 1., 0., 1., 1., 0., 1., 0.],\n",
            "        [0., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 1., 1., 1., 0., 1., 0., 0.],\n",
            "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 0., 1., 0., 0., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 1., 0., 0., 1., 1.],\n",
            "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 1.],\n",
            "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 0., 1., 0., 1., 1., 0., 0., 1.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
            "        [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],\n",
            "        [0., 1., 0., 1., 1., 1., 1., 1., 0., 1.],\n",
            "        [1., 1., 1., 1., 0., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 0., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
            "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 1., 1., 1., 0., 1., 0., 1., 1., 0.],\n",
            "        [1., 0., 1., 0., 1., 0., 1., 0., 1., 1.],\n",
            "        [0., 1., 1., 1., 0., 1., 0., 1., 1., 0.],\n",
            "        [1., 1., 0., 0., 1., 1., 1., 0., 0., 1.],\n",
            "        [1., 1., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 0., 1., 1., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 0., 1., 0., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 1., 0., 1.],\n",
            "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
            "        [0., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 0., 1., 1., 0., 1., 0., 1.],\n",
            "        [1., 0., 1., 1., 0., 0., 1., 0., 1., 1.],\n",
            "        [1., 1., 1., 1., 0., 1., 1., 0., 0., 1.]])\n",
            "Epoch 1, Loss: 1.1711089611053467\n",
            "Epoch 2, Loss: 1.0911540985107422\n",
            "Epoch 3, Loss: 1.0255839824676514\n",
            "Epoch 4, Loss: 0.9710996747016907\n",
            "Epoch 5, Loss: 0.9252055883407593\n",
            "After removing pruning:\n",
            "Parameter containing:\n",
            "tensor([[-0.0000,  0.0966,  0.0000,  0.2192,  0.0000, -0.1592,  0.1445,  0.0000,\n",
            "         -0.1152,  0.1491],\n",
            "        [-0.2022,  0.2711,  0.0000, -0.0000, -0.0923,  0.2085, -0.1367, -0.1045,\n",
            "          0.0000,  0.2627],\n",
            "        [ 0.0000, -0.1400,  0.2371, -0.0000,  0.0000, -0.0000,  0.1169, -0.1657,\n",
            "          0.3009,  0.0000],\n",
            "        [-0.2164, -0.1718, -0.0000, -0.3009,  0.1259, -0.0000,  0.2719,  0.1660,\n",
            "         -0.1415,  0.1971],\n",
            "        [-0.3033,  0.1742,  0.1375, -0.2067, -0.3116,  0.1775,  0.1264,  0.0000,\n",
            "          0.2658, -0.2274],\n",
            "        [-0.2183, -0.2342,  0.2978, -0.2814, -0.0000,  0.1558,  0.2552, -0.1205,\n",
            "          0.1963, -0.2362],\n",
            "        [ 0.0000, -0.1259,  0.2097, -0.2794,  0.2543,  0.3028,  0.1366,  0.2114,\n",
            "          0.1631, -0.2156],\n",
            "        [-0.1760,  0.1180,  0.0000,  0.2817,  0.0000,  0.1646, -0.1362, -0.0000,\n",
            "         -0.2945, -0.0982],\n",
            "        [ 0.1400,  0.2609, -0.0000, -0.1078,  0.0000,  0.0000, -0.2351, -0.1872,\n",
            "         -0.2347, -0.2065],\n",
            "        [-0.0994, -0.0000,  0.1780, -0.1204, -0.2748, -0.0000, -0.2853, -0.1684,\n",
            "         -0.2597,  0.1225],\n",
            "        [-0.3091, -0.2999,  0.0000,  0.0000,  0.2195, -0.1603, -0.2250, -0.0000,\n",
            "         -0.2739,  0.2134],\n",
            "        [ 0.0000, -0.1510, -0.0000, -0.0000, -0.0000,  0.2961,  0.1706,  0.1289,\n",
            "         -0.1679,  0.2607],\n",
            "        [-0.0000,  0.1751,  0.0000, -0.2675, -0.0000, -0.2740, -0.0000, -0.0000,\n",
            "          0.1717,  0.1123],\n",
            "        [ 0.0000, -0.1762, -0.1072, -0.1545,  0.1814,  0.2561, -0.2428, -0.2421,\n",
            "         -0.0000, -0.0000],\n",
            "        [ 0.1016, -0.1150, -0.1058, -0.2165, -0.0954, -0.0000,  0.0000,  0.2421,\n",
            "          0.2313,  0.2989],\n",
            "        [-0.2454,  0.2920, -0.3101,  0.1319, -0.2745,  0.1461, -0.0000, -0.1777,\n",
            "         -0.2393, -0.2138],\n",
            "        [ 0.1541,  0.0000,  0.2447, -0.1935, -0.1849,  0.2228,  0.1577, -0.2961,\n",
            "          0.0000, -0.0933],\n",
            "        [ 0.0000, -0.2588,  0.1467, -0.2082,  0.0000,  0.2257,  0.2977, -0.0000,\n",
            "         -0.0959,  0.0000],\n",
            "        [ 0.0000,  0.1990,  0.1027, -0.0000, -0.1825,  0.1878, -0.1247, -0.2841,\n",
            "          0.2884, -0.1058],\n",
            "        [-0.0996,  0.2180, -0.0000,  0.2643,  0.2995,  0.2556, -0.0000, -0.1364,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.2454, -0.0000,  0.1086,  0.2002, -0.3086, -0.3043,  0.1013, -0.1426,\n",
            "          0.1325,  0.0000],\n",
            "        [ 0.2814,  0.1090, -0.0000, -0.2774, -0.0000,  0.0000, -0.1115,  0.1039,\n",
            "          0.0000,  0.0000],\n",
            "        [-0.1206, -0.2053,  0.2678,  0.1312,  0.0000,  0.1920,  0.0000, -0.0000,\n",
            "          0.3108, -0.1977],\n",
            "        [ 0.0000,  0.2873,  0.0000, -0.2941,  0.3030,  0.0000, -0.2395, -0.0000,\n",
            "          0.0000,  0.1523],\n",
            "        [ 0.2680,  0.0000, -0.2012,  0.1724,  0.2371, -0.1955,  0.3135, -0.1602,\n",
            "          0.1477, -0.2450],\n",
            "        [ 0.3151, -0.1509, -0.0000, -0.2639,  0.0000, -0.2386, -0.3078,  0.0000,\n",
            "         -0.0000,  0.1597],\n",
            "        [-0.3007,  0.1314, -0.3150, -0.0000,  0.0000, -0.0000,  0.0000, -0.2591,\n",
            "          0.1481,  0.3111],\n",
            "        [-0.2727, -0.0000,  0.3137, -0.0000,  0.1548,  0.0000, -0.1832, -0.1296,\n",
            "          0.1612,  0.1547],\n",
            "        [-0.0000,  0.1407,  0.0000, -0.1349, -0.1640,  0.2153,  0.1665,  0.1965,\n",
            "         -0.0000, -0.2373],\n",
            "        [-0.2983,  0.1540, -0.1114, -0.2252,  0.0000, -0.2073,  0.1420, -0.1887,\n",
            "          0.0000,  0.1012],\n",
            "        [ 0.0000,  0.1547,  0.0000,  0.0000, -0.1802, -0.0000,  0.1146,  0.2076,\n",
            "          0.2203, -0.0000],\n",
            "        [ 0.2759,  0.1892,  0.2108,  0.2052, -0.0000, -0.2937,  0.2163,  0.1204,\n",
            "         -0.1541,  0.2464],\n",
            "        [-0.2874,  0.2156,  0.2478, -0.1560, -0.0000, -0.0000,  0.2346,  0.0000,\n",
            "         -0.3106,  0.2177],\n",
            "        [ 0.1223, -0.0000,  0.0000,  0.1751,  0.0000,  0.1770, -0.2649,  0.3071,\n",
            "         -0.0000,  0.1174],\n",
            "        [ 0.0000, -0.1407, -0.0000, -0.0000,  0.2121,  0.0000,  0.2137,  0.0000,\n",
            "          0.0000,  0.1122],\n",
            "        [-0.2089,  0.0000,  0.3063,  0.1452,  0.2966, -0.2338,  0.1946, -0.1091,\n",
            "          0.1677, -0.1417],\n",
            "        [ 0.0000,  0.1156, -0.1102, -0.2473, -0.0000, -0.1923,  0.0000,  0.1305,\n",
            "          0.2973,  0.0000],\n",
            "        [ 0.1296,  0.0000,  0.3113,  0.0000, -0.1906, -0.0000, -0.1885,  0.0000,\n",
            "          0.0984, -0.2543],\n",
            "        [ 0.0000, -0.1491, -0.2157, -0.1638, -0.0000, -0.1693, -0.0000,  0.2274,\n",
            "         -0.1976,  0.0000],\n",
            "        [ 0.0968,  0.1798, -0.0000, -0.0000, -0.1932, -0.2976, -0.1199,  0.0000,\n",
            "         -0.0000,  0.2027],\n",
            "        [ 0.1140, -0.2838,  0.2835,  0.0000, -0.0000, -0.2532, -0.1202,  0.0000,\n",
            "         -0.0955,  0.1097],\n",
            "        [-0.2345, -0.0000, -0.0000,  0.1446,  0.1226,  0.0000,  0.2767,  0.2031,\n",
            "         -0.1688,  0.1665],\n",
            "        [-0.1854,  0.1921, -0.2777, -0.0000, -0.2724,  0.0000,  0.3109, -0.1121,\n",
            "          0.0000, -0.0000],\n",
            "        [-0.2234, -0.2172, -0.1275,  0.1702,  0.2368, -0.2982,  0.1427, -0.2406,\n",
            "          0.0987, -0.2756],\n",
            "        [-0.1270, -0.1462, -0.1420, -0.1154,  0.2625, -0.0000,  0.0000,  0.1182,\n",
            "          0.0000, -0.1818],\n",
            "        [ 0.2351, -0.2400, -0.2174,  0.0000,  0.1286, -0.1108,  0.1342,  0.1123,\n",
            "         -0.2927,  0.0000],\n",
            "        [ 0.0000,  0.3039,  0.3057, -0.1601, -0.2972, -0.0000,  0.1006,  0.1208,\n",
            "         -0.1191, -0.1104],\n",
            "        [-0.1895,  0.2475,  0.1729, -0.0000,  0.0945, -0.2331,  0.0000, -0.1323,\n",
            "         -0.0000,  0.2819],\n",
            "        [-0.2339, -0.0000,  0.2053,  0.3053, -0.0000,  0.0000, -0.3025,  0.0000,\n",
            "         -0.2947,  0.2943],\n",
            "        [-0.1010, -0.2926,  0.1980,  0.1790,  0.0000,  0.1309,  0.3137,  0.0000,\n",
            "         -0.0000,  0.2370]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}